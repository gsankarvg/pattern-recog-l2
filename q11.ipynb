{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6712af67",
   "metadata": {},
   "source": [
    "11. Implement  a  Python  script  to  model  a  Markov  Decision  Process  using  a  given \n",
    "transition matrix and reward function of 3 states and 2 actions. Calculate the value \n",
    "function for each state provided the policy for all states and actions are initialized as \n",
    "0.5. Provide a sample MDP and demonstrate the corresponding value function (Set \n",
    "discount factor = 0.9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d58094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Rainy', 'Cloudy', 'Sunny']\n",
    "actions = ['Umbrella', 'No Umbrella']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59b9aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {\n",
    "    \"Rainy\": {\n",
    "        \"Umbrella\": [0.8, 0.2, 0.0],  \n",
    "        \"No Umbrella\": [0.0, 1.0, 0.0],  \n",
    "    },\n",
    "    \"Cloudy\": {\n",
    "        \"Umbrella\": [0.0, 0.9, 0.1],\n",
    "        \"No Umbrella\": [0.5, 0.0, 0.5],\n",
    "    },\n",
    "    \"Sunny\": {\n",
    "        \"Umbrella\": [0.0, 0.0, 1.0],\n",
    "        \"No Umbrella\": [0.3, 0.3, 0.4],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b41d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = {\n",
    "    \"Rainy\": {\n",
    "        \"Umbrella\": [5, 0, 0],  \n",
    "        \"No Umbrella\": [0, 10, 0],  \n",
    "    },\n",
    "    \"Cloudy\": {\n",
    "        \"Umbrella\": [0, -1, 1],\n",
    "        \"No Umbrella\": [2, 0, 2],\n",
    "    },\n",
    "    \"Sunny\": {\n",
    "        \"Umbrella\": [0, 0, 3],\n",
    "        \"No Umbrella\": [1, 1, 1],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4252d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000d3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize uniform policy: π(state, action) = 0.5\n",
    "policy = {s: {a: 0.5 for a in actions} for s in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "415c4d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rainy': {'Umbrella': 0.5, 'No Umbrella': 0.5},\n",
       " 'Cloudy': {'Umbrella': 0.5, 'No Umbrella': 0.5},\n",
       " 'Sunny': {'Umbrella': 0.5, 'No Umbrella': 0.5}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a03f296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize value function V[state] = 0\n",
    "V = {s: 0.0 for s in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70a0aab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rainy': 0.0, 'Cloudy': 0.0, 'Sunny': 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967caeb",
   "metadata": {},
   "source": [
    "The **Bellman expectation formula** for the value function under a policy π is:\n",
    "\n",
    "V<sub>π</sub>(s) = Σ<sub>a</sub> π(a|s) Σ<sub>s'</sub> P(s'|s,a) [ R(s,a,s') + γ V<sub>π</sub>(s') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "167656ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run policy evaluation\n",
    "for _ in range(20):  \n",
    "    new_V = {}\n",
    "    for s in states:\n",
    "        v = 0\n",
    "        for a in actions:\n",
    "            pi = policy[s][a]\n",
    "            for i, s_prime in enumerate(states):\n",
    "                prob = P[s][a][i]\n",
    "                reward = R[s][a][i]\n",
    "                v += pi * prob * (reward + discount_factor * V[s_prime])\n",
    "        new_V[s] = v\n",
    "    V = new_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246db919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Value Function:\n",
      "Rainy: 28.7554\n",
      "Cloudy: 21.7311\n",
      "Sunny: 22.9308\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Value Function:\")\n",
    "for s in states:\n",
    "    print(f\"{s}: {V[s]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "082cd250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function after 40 iterations:\n",
      "Rainy: 31.6656\n",
      "Cloudy: 24.6412\n",
      "Sunny: 25.8409\n"
     ]
    }
   ],
   "source": [
    "V_40 = {s: 0.0 for s in states}\n",
    "for _ in range(40):\n",
    "    new_V = {}\n",
    "    for s in states:\n",
    "        v = 0\n",
    "        for a in actions:\n",
    "            pi = policy[s][a]\n",
    "            for i, s_prime in enumerate(states):\n",
    "                prob = P[s][a][i]\n",
    "                reward = R[s][a][i]\n",
    "                v += pi * prob * (reward + discount_factor * V_40[s_prime])\n",
    "        new_V[s] = v\n",
    "    V_40 = new_V\n",
    "\n",
    "print(\"Value Function after 40 iterations:\")\n",
    "for s in states:\n",
    "    print(f\"{s}: {V_40[s]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e819deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference between 40 and 20 iterations:\n",
      "Rainy: 2.910185\n",
      "Cloudy: 2.910185\n",
      "Sunny: 2.910185\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDifference between 40 and 20 iterations:\")\n",
    "for s in states:\n",
    "    diff = V_40[s] - V[s]\n",
    "    print(f\"{s}: {diff:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
